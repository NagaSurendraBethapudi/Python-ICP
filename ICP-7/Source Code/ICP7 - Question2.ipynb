{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICP7 - Question 2\n",
    "### Extract the following web URL text using BeautifulSoupand save the result in a file “input.txt”. \n",
    "### Apply the following on the “input.txt” file https://en.wikipedia.org/wiki/Google\n",
    "1. Tokenization\n",
    "2. POS\n",
    "3. Stemming\n",
    "4. Lemmatization \n",
    "5. Trigram\n",
    "6. Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "def wiki():\n",
    "    url = \"https://en.wikipedia.org/wiki/Google\" #given url\n",
    "    source_code = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code, \"html.parser\")\n",
    "    body = soup.find('div', {'class': 'mw-parser-output'})\n",
    "    file.write(str(body.text))\n",
    "\n",
    "file = open('input.txt', 'a+', encoding='utf-8') #saving the data into input.txt\n",
    "wiki()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing NLTK - Natural Language Tool - Kit\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "data = open('input.txt', encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "stokens = nltk.sent_tokenize(data)\n",
    "wtokens = nltk.word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing sentences\n",
    "#for s in stokens:\n",
    "    #print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'article', 'is', 'about', 'the', 'company', '.', 'For', 'the', 'search', 'engine', ',', 'see', 'Google', 'Search', '.', 'For', 'other', 'uses', ',', 'see', 'Google', '(', 'disambiguation', ')', '.', 'Not', 'to', 'be', 'confused', 'with', 'Googol', 'or', 'Goggles', '.', 'American', 'technology', 'company', 'Google', 'LLCLogo', 'since', '2015', '[', 'update', ']', 'Google', \"'s\", 'headquarters', ',', 'the']\n"
     ]
    }
   ],
   "source": [
    "print(wtokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing words\n",
    "#or t in wtokens:\n",
    "    #rint(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This article is about the company.', 'For the search engine, see Google Search.', 'For other uses, see Google (disambiguation).', 'Not to be confused with Googol or Goggles.', \"American technology company\\n\\n\\nGoogle LLCLogo since 2015[update]Google's headquarters, the GoogleplexFormerlyGoogle Inc. (1998–2017)TypeSubsidiary (LLC)IndustryInternetCloud computingComputer softwareComputer hardwareArtificial intelligenceAdvertisingFoundedSeptember\\xa04, 1998; 22 years ago\\xa0(1998-09-04)[a] in Menlo Park, California, United StatesFoundersLarry PageSergey BrinHeadquarters1600 Amphitheatre Parkway, Mountain View, California, United StatesQueenstown, Singapore (Asia-Pacific)[5]Area servedWorldwideKey peopleSundar Pichai (CEO)Ruth Porat (CFO)ProductsList of productsRevenue182,527,000,000 United States dollar (2020)\\xa0Operating income41,224,000,000 United States dollar (2020)\\xa0Net income40,269,000,000 United States dollar (2020)\\xa0Total assets319,616,000,000 United States dollar (2020)\\xa0Number of employees135,301 (2020)\\xa0ParentAlphabet Inc.Websitegoogle.comFootnotes\\xa0/ references[6][7][8][9]\\nGoogle LLC is an American multinational technology company that specializes in Internet-related services and products, which include online advertising technologies, a search engine, cloud computing, software, and hardware.\", 'It is considered one of the Big Five technology companies in the U.S. information technology industry, alongside Amazon, Facebook, Apple, and Microsoft.', '[10][11][12]\\nGoogle was founded in September 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University in California.', 'Together they own about 14 percent of its shares and control 56 percent of the stockholder voting power through supervoting stock.', 'They incorporated Google as a California privately held company on September 4, 1998.', 'Google was then reincorporated in Delaware on October 22, 2002.']\n"
     ]
    }
   ],
   "source": [
    "print(stokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.POS (Part of Speech Tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence    :  This article is about the company.\n",
      "[('T', 'NNP'), ('h', 'NN'), ('i', 'NN'), ('s', 'VBP'), (' ', 'PDT'), ('a', 'DT'), ('r', 'NN'), ('t', 'NN'), ('i', 'NN'), ('c', 'VBP'), ('l', 'NN'), ('e', 'NN'), (' ', 'NN'), ('i', 'NN'), ('s', 'VBP'), (' ', 'PDT'), ('a', 'DT'), ('b', 'NN'), ('o', 'NN'), ('u', 'JJ'), ('t', 'NN'), (' ', 'NNP'), ('t', 'NN'), ('h', 'NN'), ('e', 'NN'), (' ', 'NNP'), ('c', 'VBZ'), ('o', 'JJ'), ('m', 'NN'), ('p', 'VBZ'), ('a', 'DT'), ('n', 'JJ'), ('y', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#POS Part of Speech tagging\n",
    "n = 0\n",
    "for s in stokens:\n",
    "    n = n + 1\n",
    "    if n < 2:\n",
    "        print('Sentence    : ', s)\n",
    "        print(nltk.pos_tag(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pStemmer = PorterStemmer()\n",
    "lStemmer = LancasterStemmer()\n",
    "sStemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pStemmer :  thi\n",
      "lStemmer :  thi\n",
      "sStemmer :  this\n",
      "pStemmer :  articl\n",
      "lStemmer :  artic\n",
      "sStemmer :  articl\n",
      "pStemmer :  is\n",
      "lStemmer :  is\n",
      "sStemmer :  is\n",
      "pStemmer :  about\n",
      "lStemmer :  about\n",
      "sStemmer :  about\n",
      "pStemmer :  the\n",
      "lStemmer :  the\n",
      "sStemmer :  the\n"
     ]
    }
   ],
   "source": [
    "n1 = 0\n",
    "for t in wtokens:\n",
    "    n1 = n1 + 1\n",
    "    if n1 < 6:\n",
    "        print('pStemmer : ' ,pStemmer.stem(t))\n",
    "        print('lStemmer : ' ,lStemmer.stem(t))\n",
    "        print('sStemmer : ' ,sStemmer.stem(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "#Importing required Libraries\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizer: This\n",
      "Lemmatizer: article\n",
      "Lemmatizer: is\n",
      "Lemmatizer: about\n",
      "Lemmatizer: the\n"
     ]
    }
   ],
   "source": [
    "n1 = 0\n",
    "for w in wtokens:\n",
    "    n1 = n1 + 1\n",
    "    if n1 < 6:\n",
    "        print('Lemmatizer:', lemmatizer.lemmatize(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming vs Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google\n"
     ]
    }
   ],
   "source": [
    "# Stemming Vs Lemmatization\n",
    "# Took one word from data(Input)\n",
    "import random\n",
    "print(random.choice(wtokens)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work\n",
      "worker\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem('workers'))\n",
    "print(lemmatizer.lemmatize('workers'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required Libraries\n",
    "from nltk.util import ngrams\n",
    "token = nltk.word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence    :  This article is about the company.\n",
      "word tokens :  ['This', 'article', 'is', 'about', 'the', 'company', '.']\n",
      "bigrams     :  [('This', 'article'), ('article', 'is'), ('is', 'about'), ('about', 'the'), ('the', 'company'), ('company', '.')]\n",
      "trigrams    :  [('This', 'article', 'is'), ('article', 'is', 'about'), ('is', 'about', 'the'), ('about', 'the', 'company'), ('the', 'company', '.')]\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for s in stokens:\n",
    "    n = n + 1\n",
    "    if n < 2:\n",
    "        print('Sentence    : ', s)\n",
    "        token = nltk.word_tokenize(s)\n",
    "        print('word tokens : ', token)\n",
    "        bigrams = list(ngrams(token, 2))\n",
    "        print('bigrams     : ', bigrams)\n",
    "        trigrams = list(ngrams(token, 3))\n",
    "        print('trigrams    : ', trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Named Entity Recognition\n",
    "#Importing required libraries\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article is about the company.\n",
      "(S This/DT article/NN is/VBZ about/IN the/DT company/NN ./.)\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for s in stokens:\n",
    "    n = n + 1\n",
    "    if n < 2:\n",
    "        print(s)\n",
    "        print(ne_chunk(pos_tag(word_tokenize(s))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
